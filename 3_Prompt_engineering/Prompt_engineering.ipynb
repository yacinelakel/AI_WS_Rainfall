{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 0. Initialization\n",
    "To get started we need to import relevant libraries and a valid OpenAI key.\n",
    "For convenience we also define a helper function to simplify calling the OpenAI ChatCompletion API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# OpenAI initialisation and additional dependencies\n",
    "import os\n",
    "import openai\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function for calling ChatCompletion API\n",
    "\n",
    "# Alternative models to try: gpt-4-1106-preview, gpt-4, gpt-3.5-turbo-0125, gpt-3.5-turbo, gpt-3.5-turbo-0613\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Three key prompt engineering strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.1 Zero-Shot Prompting\n",
    "\n",
    "Large LLMs today, such as ChatGPT, are tuned to follow instructions and are trained on large amounts of data. Therefore, they are capable of performing some tasks \"zero-shot.\". This means that the model can perform a task without any fine-tuning or training on the task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Zero-shot example: translation\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Translate the following English text to Spanish and English pirate: \\ \n",
    "```Hello, I would like to purchase an insurance package.```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that in the prompt above we didn't provide the model with any examples, the LLM already understands the relevant aspects. That's the zero-shot capabilities at work.\n",
    "\n",
    "\n",
    "When zero-shot doesn't work, it's recommended to provide demonstrations or examples in the prompt which leads us to few-shot prompting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.2 Few-Shot Prompting\n",
    "\n",
    "While LLMs demonstrate remarkable zero-shot capabilities, they still fall short on more complex tasks when using zero-shot prompting. Few-shot prompting can be used as a technique to enable in-context learning where we provide demonstrations in the prompt to steer the model to better performance. The demonstrations serve as conditioning for subsequent examples where we would like the model to generate a response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Lets say you are a basketball manufacturer and want to make a sentiment analysis based on customer reviews. You can use few-shot prompting to steer the model to better performance. Here is an example of how you can do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral\n"
     ]
    }
   ],
   "source": [
    "# Zero-shot attempt\n",
    "prompt = f\"\"\"\n",
    "Determine the sentiment of this sentence.\n",
    "Sentence: This basketball has a lot of weight.\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Even though the model classifies the review as neutral, a basketball with a lot of weight might be a faulty product. Therefore, we can use few-shot prompting to steer the model to better performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of this sentence is negative.\n"
     ]
    }
   ],
   "source": [
    "# Few-shot attempt\n",
    "prompt = f\"\"\"\n",
    "Sentence: This basketball is easy to carry.\n",
    "\n",
    "Answer: The sentiment of this sentence is positive.\n",
    "\n",
    "Determine the sentiment of the sentence.\n",
    "\n",
    "Sentence: This basketball has a lot of weight.\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This time the model classifies the review as 'negative' as it uses the provided example as a reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Even though few-shot prompting is a powerful technique, it has some limitations - as shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 3:\n",
      "The average is 77906.5.\n"
     ]
    }
   ],
   "source": [
    "# Unsuccessful few-shot attempt at average calculation\n",
    "prompt = f\"\"\"\n",
    "You are an AI assistant capable of performing complex  numerical computations.\n",
    "\n",
    "Question 1:\n",
    "Find the average of the numbers. Here are the numbers: 1, 2, 3.\n",
    "\n",
    "Answer 1:\n",
    "The average is 2.\n",
    "\n",
    "Question 2:\n",
    "Find the average of the numbers. Here are the numbers: 5, 10, 15, 7.\n",
    "\n",
    "Answer 2:\n",
    "The average is 9.25.\n",
    "\n",
    "Question 3:\n",
    "Find the average of the numbers. Here are the numbers: 63409, 95328, 45860, 91378, 210691, 50923, 50760, 99145.\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88436.75"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the calculation: \n",
    "x = [63409, 95328, 45860, 91378, 210691, 50923, 50760, 99145]\n",
    "sum(x)/len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As we can see this is not the correct response and there is a need for more advanced prompt engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.3 Chain-of-thoughts prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Chain of thought prompting enables complex reasoning capabilities through intermediate reasoning steps. You can combine it with few-shot prompting to get better results on more complex tasks that require reasoning before responding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Answer 3:\\n'\n",
      " 'We start by finding the sum of the numbers. \\n'\n",
      " '63409+95328=158737\\n'\n",
      " '158737+45860=204597\\n'\n",
      " '204597+91378=295975\\n'\n",
      " '295975+210691=506666\\n'\n",
      " '506666+50923=557589\\n'\n",
      " '557589+50760=608349\\n'\n",
      " '608349+99145=707494\\n'\n",
      " '\\n'\n",
      " 'The sum of the numbers is 707494. \\n'\n",
      " 'Then we divide the sum by the number of numbers. \\n'\n",
      " '707494/8=88436.75\\n'\n",
      " 'The average is 88436.75.')\n"
     ]
    }
   ],
   "source": [
    "# Average calculation with combined few-shot and chain-of-thoughts prompting\n",
    "prompt = f\"\"\"\n",
    "You are an AI assistant capable of performing complex  numerical computations.\n",
    "\n",
    "Question 1:\n",
    "Find the average of the numbers. Here are the numbers: 1, 2, 3.\n",
    "\n",
    "Answer 1:\n",
    "We start by finding the sum of the numbers. 1+2=3, 3+3=6. The sum of the numbers is 6. Then we divide the sum by the number of numbers. 6/3=2. The average is 2.\n",
    "\n",
    "Question 2:\n",
    "Find the average of the numbers. Here are the numbers: 5, 10, 15, 7.\n",
    "\n",
    "Answer 2:\n",
    "We start by finding the sum of the numbers. 5+10=15, 15+15=30, 30+7=37. The sum of the numbers is 37. Then we divide the sum by the number of numbers. 37/4=9.25. The average is 9.25.\n",
    "\n",
    "Question 3:\n",
    "Find the average of the numbers. Here are the numbers: 63409, 95328, 45860, 91378, 210691, 50923, 50760, 99145.\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As we can see, the model is able to reason about the question and provide a correct answer when given more detailed instructions on how to solve the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Basic prompt engineering principles, with some illustrations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.1 Principle 1: Write clear and specific instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tactic 1 - Use delimiters to clearly indicate distinct parts of the input\n",
    "By using delimiters you can clearly indicate distinct parts of the input. Delimiters can be anything like: ```, \"\"\", < >, `<tag> </tag>`, `:`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To ensure a model works effectively, provide clear and specific instructions to avoid mistakes and achieve accurate results, even if it means using longer prompts for better outcomes.\n"
     ]
    }
   ],
   "source": [
    "# Delimiter usage example\n",
    "\n",
    "text = \"\"\"\n",
    "For a model to work well, just be really clear \\ \n",
    "about what you want. Give specific instructions \\ \n",
    "so the model knows exactly what to do. This helps \\ \n",
    "get the right answers and avoids mistakes. Remember, \\ \n",
    "a short prompt isn't always a clear one. Sometimes, \\ \n",
    "it's better to use longer prompts to give more \\ \n",
    "info to the model. This usually leads to better \\ \n",
    "and more relevant results.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\ \n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tactic 2 - Ask for a structured output\n",
    "By asking for a structured output you can get output that is easier to parse and use in your application. This is especially useful when you want to use the output in a downstream task. Examples of structured output are JSON and HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"product_id\": 1,\n",
      "        \"name\": \"CashFlow Pro\",\n",
      "        \"developer\": \"FinTech Innovations Inc.\",\n",
      "        \"category\": \"Personal Finance Management\"\n",
      "    },\n",
      "    {\n",
      "        \"product_id\": 2,\n",
      "        \"name\": \"SecureSave\",\n",
      "        \"developer\": \"CyberGuard Solutions\",\n",
      "        \"category\": \"Online Banking Security\"\n",
      "    },\n",
      "    {\n",
      "        \"product_id\": 3,\n",
      "        \"name\": \"InvestWise\",\n",
      "        \"developer\": \"WealthTech Solutions\",\n",
      "        \"category\": \"Investment Management\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Example asking for structured (JSON) output\n",
    "prompt = f\"\"\"\n",
    "Generate a list of three fictional banking product names along with their developers and categories. \n",
    "Provide them in JSON format with the following keys: product_id, name, developer, category.\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tactic 3 - Ask the model to check whether conditions are satisfied\n",
    "The model can be asked to make reasoning steps, for example check if a condition is satisfied and perform an action depending on the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 - Identify the type of coverage you need.\n",
      "Step 2 - Gather relevant information about your assets and risks.\n",
      "Step 3 - Choose a reputable insurance provider and select a suitable policy.\n",
      "Step 4 - Complete the application process.\n",
      "Step 5 - Wait for the policy to be approved.\n",
      "Step 6 - Review the terms and conditions carefully after approval.\n",
      "Step 7 - Make the required payments to activate your coverage.\n",
      "Step 8 - Consult with an insurance agent for clarification if needed.\n"
     ]
    }
   ],
   "source": [
    "# Example asking the model to check a condition - part 1 - condition met\n",
    "text_1 = f\"\"\"\n",
    "Understanding Insurance Basics is Simple! First, identify the type of coverage you need. \n",
    "While doing that, gather relevant information about your assets and risks. \n",
    "Next, choose a reputable insurance provider and select a suitable policy. \n",
    "Once you've made your decision, go ahead and complete the application process. \n",
    "Wait for the policy to be approved. After approval, review the terms and conditions carefully. \n",
    "If everything looks good, make the required payments to activate your coverage. \n",
    "If needed, consult with an insurance agent for clarification. \n",
    "And there you have it! You've successfully secured insurance coverage for your peace of mind.\n",
    "\"\"\"\n",
    "\n",
    "# prompt with a conditional instruction + text input\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \\ \n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions, \\ \n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No steps provided.\n"
     ]
    }
   ],
   "source": [
    "# Example asking the model to check a condition - part 2 - condition not met\n",
    "text_2 = f\"\"\"\n",
    "The stock market is buzzing with activity today, and financial analysts are deep in discussions. \n",
    "It's an intriguing day to explore the dynamics of the financial world. \n",
    "The charts are fluctuating, and economic indicators are being closely monitored. \n",
    "Traders are making strategic moves, and investors are assessing their portfolios. \n",
    "Some are engaged in intense conversations about market trends, while others are researching potential investment opportunities. \n",
    "It's an ideal day to delve into the intricacies of finance and witness the ebb and flow of economic activities.\n",
    "\"\"\"\n",
    "\n",
    "# prompt with a conditional instruction + text input\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \\ \n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions, \\ \n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tactic 4 - Providing examples\n",
    "By giving the model a few examples of the desired output, it can learn to generalize to similar cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<financial_advisor>: Risk management is the process of identifying, assessing, and prioritizing risks followed by coordinated and economical application of resources to minimize, monitor, and control the probability and impact of unfortunate events. It is essential in ensuring the protection and sustainability of your financial assets.\n"
     ]
    }
   ],
   "source": [
    "# Providing a sample conversation\n",
    "prompt = f\"\"\"\n",
    "Your task is to answer in a consistent style.\n",
    "\n",
    "<client>: Enlighten me about financial planning.\n",
    "\n",
    "<financial_advisor>: The fortune that grows most steadily \\\n",
    "emanates from disciplined savings; the \\\n",
    "most prosperous investment portfolio begins with a single asset; \\\n",
    "the most secure financial future starts with a well-laid plan.\n",
    "\n",
    "<client>: Enlighten me about risk management.\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.2 Principle 2: Give the model time to “think” "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tactic 1 - Specify the steps required to complete a task\n",
    "By specifying the steps required to complete a task, the model can learn to perform the task step-by-step instead of rushing to a conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Alex and Emma sought insurance coverage for their family, faced challenges understanding the terms, sought help from advisors, and left with a sense of security.\n",
      "\n",
      "2 - Alex et Emma ont cherché une couverture d'assurance pour leur famille, ont rencontré des défis pour comprendre les termes, ont demandé de l'aide à des conseillers, et sont partis avec un sentiment de sécurité.\n",
      "\n",
      "3 - Alex, Emma\n",
      "\n",
      "4 - \n",
      "{\n",
      "  \"french_summary\": \"Alex et Emma ont cherché une couverture d'assurance pour leur famille, ont rencontré des défis pour comprendre les termes, ont demandé de l'aide à des conseillers, et sont partis avec un sentiment de sécurité.\",\n",
      "  \"num_names\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example using complex (and slightly pointless) step by step instructions\n",
    "\n",
    "text = f\"\"\"\n",
    "In a bustling city, siblings Alex and Emma embarked on \\\n",
    "a mission to secure insurance coverage for their \\\n",
    "family. As they navigated the policy options, discussing earnestly, uncertainty \\\n",
    "struck—Alex faced unexpected challenges understanding the terms \\\n",
    "of coverage, and Emma encountered confusing jargon. \\\n",
    "Though slightly perplexed, the duo sought assistance from \\\n",
    "knowledgeable advisors. Despite the confusion, \\\n",
    "their determined efforts prevailed, and they \\\n",
    "left the insurance agency with a sense of security and understanding.\n",
    "\"\"\"\n",
    "\n",
    "# step-by-step instructions:\n",
    "prompt_1 = f\"\"\"\n",
    "Perform the following actions: \n",
    "1 - Summarize the following text delimited by triple \\\n",
    "backticks with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a json object that contains the following \\\n",
    "keys: french_summary, num_names.\n",
    "\n",
    "Separate your answers with line breaks.\n",
    "\n",
    "Text:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt_1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tactic 2 - Instruct the model to work out its own solution before rushing to a conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<center><img src=\"resources/Thinking-Fast-and-Slow.jpg\" alt=\"Prompting principle 2: time to think\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can all be prone to jumping to conclusions. The same is true for models. By instructing the model to work out its own solution before rushing to a conclusion, we can avoid this problem. In this example we can see the model being \"tempted\" by an easy solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"The student's solution is incorrect. \\n\"\n",
      " '\\n'\n",
      " 'The correct total budget for the first year of operations as a function of '\n",
      " 'the number of square feet should be:\\n'\n",
      " 'Total cost = Office cost + Computer equipment cost + IT support cost\\n'\n",
      " 'Total cost = $50x + $200x + $80,000 + $15x\\n'\n",
      " 'Total cost = $265x + $80,000\\n'\n",
      " '\\n'\n",
      " 'Therefore, the correct total budget for the first year of operations as a '\n",
      " 'function of the number of square feet is $265x + $80,000.')\n"
     ]
    }
   ],
   "source": [
    "# jumping to wrong conclusion\n",
    "prompt = f\"\"\"\n",
    "Your task is to determine if the student's solution \\\n",
    "is correct or not.\n",
    "\n",
    "Question:\n",
    "```\n",
    "I'm starting a financial consultancy and need assistance\n",
    "working out the budget.\n",
    "- Office space rental costs $50 / square foot \n",
    "- I can purchase computer equipment for $200 / square foot\n",
    "- I negotiated an annual contract for IT support that will cost\n",
    "me a flat $80k per year, and an additional $15 / square\n",
    "foot\n",
    "What is the total budget for the first year of operations\n",
    "as a function of the number of square feet?\n",
    "``` \n",
    "Student's solution:\n",
    "```\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Office cost: 50x\n",
    "2. Solar panel cost: 200x\n",
    "3. Maintenance cost: 80,000 + 150x\n",
    "Total cost: 50x + 200x + 80,000 + 150x = 400x + 80,000\n",
    "\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "Note that the student's solution is actually not correct. We can fix this by instructing the model to work out its own solution first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's calculate the total budget for the first year of operations as a function of the number of square feet.\n",
      "\n",
      "Given:\n",
      "- Office space rental costs $50 / square foot\n",
      "- Computer equipment costs $200 / square foot\n",
      "- IT support contract: $80,000 flat fee + $15 / square foot\n",
      "\n",
      "Let x be the size of the installation in square feet.\n",
      "\n",
      "Costs:\n",
      "1. Office cost: $50x\n",
      "2. Computer equipment cost: $200x\n",
      "3. IT support cost: $80,000 + $15x\n",
      "\n",
      "Total cost: $50x + $200x + $80,000 + $15x = $265x + $80,000\n",
      "\n",
      "Therefore, the total budget for the first year of operations as a function of the number of square feet is $265x + $80,000.\n",
      "\n",
      "Is the student's solution the same as the actual solution just calculated:\n",
      "```\n",
      "No\n",
      "```\n",
      "Student grade:\n",
      "```\n",
      "Incorrect\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# thinking things through, and getting it right\n",
    "prompt = f\"\"\"\n",
    "Your task is to determine if the student's solution \\\n",
    "is correct or not.\n",
    "To solve the problem do the following:\n",
    "- First, work out your own solution to the problem including the final total. \n",
    "- Then compare your solution to the student's solution \\ \n",
    "and evaluate if the student's solution is correct or not. \n",
    "Don't decide if the student's solution is correct until \n",
    "you have done the problem yourself.\n",
    "\n",
    "Use the following format:\n",
    "Question:\n",
    "```\n",
    "question here\n",
    "```\n",
    "Student's solution:\n",
    "```\n",
    "student's solution here\n",
    "```\n",
    "Actual solution:\n",
    "```\n",
    "steps to work out the solution and your solution here\n",
    "```\n",
    "Is the student's solution the same as actual solution \\\n",
    "just calculated:\n",
    "```\n",
    "yes or no\n",
    "```\n",
    "Student grade:\n",
    "```\n",
    "correct or incorrect\n",
    "```\n",
    "\n",
    "Question:\n",
    "```\n",
    "I'm starting a financial consultancy and need assistance\n",
    "working out the budget.\n",
    "- Office space rental costs $50 / square foot \n",
    "- I can purchase computer equipment for $200 / square foot\n",
    "- I negotiated an annual contract for IT support that will cost\n",
    "me a flat $80k per year, and an additional $15 / square\n",
    "foot\n",
    "What is the total budget for the first year of operations\n",
    "as a function of the number of square feet?\n",
    "``` \n",
    "Student's solution:\n",
    "```\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Office cost: 50x\n",
    "2. Solar panel cost: 200x\n",
    "3. Maintenance cost: 80,000 + 150x\n",
    "Total cost: 50x + 200x + 80,000 + 150x = 400x + 80,000\n",
    "```\n",
    "Actual solution:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Prompting examples for common LLM tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.1 Summarizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Basic summarization using word, sentence or character limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Sample text for summary examples\n",
    "prod_review = \"\"\"\n",
    "Acquired this 'FjordGuard Assurance' policy for my family's financial security, and they find it reassuring. \n",
    "The coverage is comprehensive, and the policy terms are transparent. The customer service has a welcoming approach, providing a sense of trust. \n",
    "However, I feel the premium is a bit high for the coverage offered. \n",
    "There might be other insurance options with more extensive benefits at a similar cost. \n",
    "Surprisingly, the policy documentation arrived a day earlier than expected, allowing me to review it thoroughly before presenting it to my family.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"The 'FjordGuard Assurance' policy offers comprehensive coverage with \"\n",
      " 'transparent terms and excellent customer service, but the premium may be '\n",
      " 'high compared to other options. Arrived early for review.')\n"
     ]
    }
   ],
   "source": [
    "# Straightforward summary\n",
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review. \n",
    "\n",
    "Summarize the review below, delimited by triple \n",
    "backticks, in at most 30 words. \n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "pprint(response, width=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Summarize with a specific focus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can ask for a summary with specific focus, getting a different response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The policy documentation arrived earlier than expected, allowing for '\n",
      " 'thorough review. Premium cost is perceived as high compared to coverage.')\n"
     ]
    }
   ],
   "source": [
    "# Summary with specific focus\n",
    " \n",
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review to give feedback to the \\\n",
    "Shipping deparmtment. \n",
    "\n",
    "Summarize the review below, delimited by triple \n",
    "backticks, in at most 30 words, and focusing on any aspects \\\n",
    "that mention shipping and delivery of the product. \n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "pprint(response, width=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As we can see the summaries include topics that are not related to the topic of focus. Changing the wording of the prompt can sometimes result in better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Feedback: The customer received the policy documentation a day earlier than '\n",
      " 'expected, which was appreciated. Consider exploring insurance options with '\n",
      " 'more extensive benefits at a similar cost.')\n"
     ]
    }
   ],
   "source": [
    "# Asking for information extract instead of a summary\n",
    "prompt = f\"\"\"\n",
    "Your task is to extract relevant information from \\ \n",
    "a product review to give \\\n",
    "feedback to the Shipping department. \n",
    "\n",
    "From the review below, delimited by triple quotes \\\n",
    "extract the information relevant to shipping and \\ \n",
    "delivery. Limit to 30 words. \n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "pprint(response, width=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.2 Inferring and categorising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A standard NLP problem is sentiment analysis and we can use LLMs to perform this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Sample review text\n",
    "review = \"\"\"\n",
    "Needed a reliable financial advisor for my investments, and NordWealth stood out with additional services and reasonable fees. After purchasing their comprehensive financial planning package, the onboarding process was swift. The communication channel broke during the initial consultation, and the company promptly arranged for a follow-up. The financial plan was delivered within a few days, and the advisor explained it thoroughly. Setting up the investment portfolio was a breeze. I encountered a minor issue, so I contacted their support, and they promptly resolved the matter. NordWealth appears to be an excellent financial service provider that prioritizes its clients and their financial goals!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "# Review sentiment determined using LLM\n",
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following review, \n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Give your answer as a single word, either \"positive\" \\\n",
    "or \"negative\".\n",
    "\n",
    "Review text: '''{review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Another powerful application of LLMs is to extract information from reviews. This can be useful for example when you want to extract information about a product or service from reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This prompt is taken directly from the DeepLearning course.\n",
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text: \n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Item\" and \"Brand\" as the keys. \n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "  \n",
    "Review text: '''{review}'''\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "LLMs are also useful for categorising and labelling text according to content, as illustrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Sample input text\n",
    "story = \"\"\"\n",
    "In a recent governmental survey examining employee satisfaction within the Norwegian financial landscape, participants were tasked with evaluating their contentment levels within their respective banking institutions. The findings illuminated that NorthHarbor Financial Alliance emerged as the leading institution, securing a commendable satisfaction rating of 85%.\n",
    "\n",
    "One employee from NorthHarbor Financial Alliance, Isabella Nordstrøm, shared her perspective on the results, stating, \"The recognition of NorthHarbor doesn't come as a surprise. It's a remarkable workplace with a collaborative culture and ample growth opportunities. I take pride in contributing to such a distinguished financial institution.\"\n",
    "\n",
    "The positive outcomes were warmly embraced by NorthHarbor Financial Alliance's leadership, with CEO Anders Olsen expressing, \"We are elated to witness such robust levels of satisfaction among our dedicated team. Our collective efforts consistently aim for excellence, and it's genuinely fulfilling to see our workforce's contributions acknowledged.\"\n",
    "\n",
    "Conversely, the survey spotlighted that Nordic Finance Collective exhibited the lowest satisfaction rating, with only 38% of employees expressing contentment in their roles. In response, the government has committed to addressing the concerns raised in the survey and is actively working toward enhancing overall job satisfaction throughout the financial sector.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Extracting topics from text using LLM\n",
    "prompt = f\"\"\"\n",
    "Determine five topics that are being discussed in the \\\n",
    "following text, which is delimited by triple backticks.\n",
    "\n",
    "Make each item one or two words long. \n",
    "\n",
    "Format your response as a list of items separated by commas.\n",
    "\n",
    "Text sample: '''{story}'''\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.3 Transforming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "LLM's are trained on many different sources in many languages - this gives the model the ability to do translations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# effortless translation\n",
    "prompt = f\"\"\"\n",
    "Translate the following English text to Spanish and English pirate: \\ \n",
    "```Hello, I would like to purchase an insurance package.```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Writing can vary in tone and should be based on the intended audience. LLMs are very efficient in changing the tone of a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# changing tone of voice\n",
    "prompt = f\"\"\"\n",
    "Translate the following from slang to a business letter: \n",
    "'Dude! Joey here. Check out the specs for this savings account.'\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "pprint(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
