{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d54fad7-f33e-4ac5-8beb-b7062d69f9cb",
   "metadata": {},
   "source": [
    "# **Important**: Run the cell below to load the OpenAI API key for the rest of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94f3f21-99b8-4b01-97c1-5a54c6a3b4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from typing import Optional\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "doc_address = 'resources/Noria_eBook_The_Insurance_Industry_2025_171205_v8.pdf' #PDF file address for question answering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ab5f86-7fee-4171-82b8-f8f59d55c217",
   "metadata": {},
   "source": [
    "# What is Retrieval Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313f1923-fdd3-40be-af11-4a81470bdec4",
   "metadata": {},
   "source": [
    "LLMs are limited in their knowldege, meaning that they don't have access to data outside their training set. This limits their ability to present new and updated info out of the box wihtout having a context about certain topics. In this section, we cover how can one provide outside context for LLMs to take advantage of their reasoning to answer questions based on accurate sources of information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2f4bcf-49e6-4079-a639-fe8ccad861f1",
   "metadata": {},
   "source": [
    "Retrieval Augmented Generation (RAG) involves enhancing the knowledge of Language Model (LLM) by incorporating additional data. Although LLMs can handle a diverse range of topics, their understanding is confined to publicly available information up to a designated training point. To enable AI applications to reason about private or post-cutoff date data, it is necessary to supplement the model's knowledge with the specific information required. This process, referred to as Retrieval Augmented Generation (RAG), involves retrieving and incorporating relevant information into the model prompt.\n",
    "\n",
    "LangChain encompasses various components specifically designed to facilitate the development of Q&A applications and, more broadly, RAG applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d0fd1-2f9a-4860-82d0-c817ebc5ede4",
   "metadata": {},
   "source": [
    "## A RAG consists of two main parts:\n",
    "### Retrieval and generation\n",
    "#### 1. Retrieve: Given a user input, relevant splits are retrieved from storage using a Retriever.\n",
    "#### 2. Generate: A ChatModel / LLM produces an answer using a prompt that includes the question and the retrieved data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9469c5a7-f6bf-47ce-8610-f569c19bdcbd",
   "metadata": {},
   "source": [
    "<div style=\"display: flex;  height: 500px;\">\n",
    "    <img src=\"resources/RAG.png\"  style=\"margin-left:auto; margin-right:auto\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67bec55-c5cd-4d5a-a8b6-b808bc3018ca",
   "metadata": {},
   "source": [
    "We will go through each step and build a RAG system using langchain to chat with a PDF file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ef74de-6fa7-42af-a754-9eceb42f49bd",
   "metadata": {},
   "source": [
    "# 1. Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e02a0f8-3629-43eb-916a-ea75f5b39d00",
   "metadata": {},
   "source": [
    "In this usecase we take a look at retrieval from a pdf file. The same technique can be extended for data in a database, or a website, etc.\n",
    "The first step is to preprocess the pdf file. This process is usually done in three steps:\n",
    "\n",
    "1. **Load**: First we need to load our data. This is done with ```DocumentLoaders```.\n",
    "2. **Split**: Text splitters break large ```Documents``` into smaller chunks. This is useful both for indexing data and for passing it in to a model, since large chunks are harder to search over and won’t fit in a model’s finite context window.\n",
    "3. **Store**: We need somewhere to store and index our splits, so that they can later be searched over. This is often done using a VectorStore and Embeddings model.\n",
    "\n",
    "We will go through each step and write a code block to perform them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2d7681-29b0-4a30-9332-d772d2d1b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83eec37-96b2-4f8d-920b-6772d1f04d3a",
   "metadata": {},
   "source": [
    "A sample PDF document is provided. The document is 25 pages and contains lots of text. The length of the documents prevents it to be fed directly to an LLM. Therefore some splitting and indexing is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b805fef-bcc4-4761-926f-fa2b7115afef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, IFrame\n",
    "\n",
    "# Specify the path to your PDF file\n",
    "pdf_path = doc_address\n",
    "\n",
    "# Create an IFrame to embed the PDF viewer\n",
    "pdf_viewer_iframe = IFrame(src=pdf_path, width=1100, height=900)\n",
    "\n",
    "# Display the IFrame\n",
    "pdf_viewer_iframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767931fc-5998-4fb9-b959-320322575d69",
   "metadata": {},
   "source": [
    "## 1.1 Load the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bb154a-1a9a-49fd-9234-af2f3a56ff99",
   "metadata": {},
   "source": [
    "<div style=\"display: flex;  height: 500px;\">\n",
    "    <img src=\"resources/doc_load.png\"  style=\"margin-left:auto; margin-right:auto\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d763aa9b-e3b8-4d32-9051-bc50c8d79037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "# Decode the file\n",
    "loader = PyPDFLoader(doc_address)\n",
    "\n",
    "# Check out the text from the PDF\n",
    "loader.load()[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193e72bd-0cd4-444b-bca5-913fb1aefa0f",
   "metadata": {},
   "source": [
    "## 1.2 Split the text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095d9f98-58e3-4648-887c-05b279a992d4",
   "metadata": {},
   "source": [
    "<div style=\"display: flex;  height: 500px;\">\n",
    "    <img src=\"resources/doc_split.png\"  style=\"margin-left:auto; margin-right:auto\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf71caa-22b3-4ff7-86db-18df1f48f43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "pages = loader.load()\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "\n",
    "\n",
    "# Split the document into chunks\n",
    "splits = text_splitter.split_documents(pages)\n",
    "\n",
    "splits[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7318ebf3-eece-4c15-9121-9a335a2fd9de",
   "metadata": {},
   "source": [
    "## 1.3 Embed and store the text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c894c99-438e-4ec9-bc80-1f04803d83ea",
   "metadata": {},
   "source": [
    "<div style=\"display: flex;  height: 500px;\">\n",
    "    <img src=\"resources/doc_embed_store.png\"  style=\"margin-left:auto; margin-right:auto\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14b43b4-63af-4d8e-bd09-9550ed32b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "# Define the embedding function for the document text\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Create a Chroma vector for searching the documents\n",
    "docsearch = Chroma.from_documents(splits,\n",
    "                                 embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc5b157-590e-4306-8f06-4539da264c89",
   "metadata": {},
   "source": [
    "A sample embedding vector for one of the splits is shown in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975a3e7f-5d4e-4e6f-bae3-ac1167a69c0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "docsearch.get([docsearch.get()['ids'][5]], include=['embeddings', 'documents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3b1523-ded4-4af5-bc25-341bd8761a0c",
   "metadata": {},
   "source": [
    "You can search for different questions ans the nearest splits with context will be queried using the ```Chroma``` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6291949-1f95-4548-8745-1f3ae00a1f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch.as_retriever().get_relevant_documents('What is Peer-to-Peer (P2P) Insurance?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a8e72e-baa1-48b5-9011-c38f13e1a0b9",
   "metadata": {},
   "source": [
    "# 2. RAG Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e62bb52-9fa4-407b-a290-30c9eb5b8621",
   "metadata": {},
   "source": [
    "<div style=\"display: flex;  height: 500px;\">\n",
    "    <img src=\"resources/RAG_agent.png\"  style=\"margin-left:auto; margin-right:auto\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6fc54b-3ae0-4e77-9184-8b1907b60099",
   "metadata": {},
   "source": [
    "Next, we use the ```LangGraph``` showcased in previous notebook to build a langchain agent which has access to the retrieval engine defined as a tool. To achieve this we follow two steps:\n",
    "\n",
    "1. Define the retrieval tool using ```langchain``` built-in functions.\n",
    "2. Create the agent pipline graph using ```LangGraph```.\n",
    "\n",
    "The code for steps above is written in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa448b8-baaf-47d6-bab7-c897299a68a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain_core.messages import BaseMessage, FunctionMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import ToolInvocation\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"Page {page}: {page_content}\")\n",
    "doc_sep = '========='\n",
    "\n",
    "tool = create_retriever_tool(\n",
    "    docsearch.as_retriever(),\n",
    "    \"retrieve_insurance_doc\",\n",
    "    \"Use this tool to answer any question about the insurance and finance using the Noria documents\",\n",
    "    document_prompt= prompt,\n",
    "    document_separator=doc_sep\n",
    ")\n",
    "\n",
    "tools = [tool]\n",
    "\n",
    "# We will set streaming=True so that we can stream tokens\n",
    "model = ChatOpenAI(temperature=0, streaming=True)\n",
    "\n",
    "functions = [format_tool_to_openai_function(t) for t in tools]\n",
    "\n",
    "model_with_functions = model.bind_functions(functions)\n",
    "\n",
    "tool_executor = ToolExecutor(tools)\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n",
    "\n",
    "\n",
    "### Edges\n",
    "\n",
    "\n",
    "def should_retrieve(state):\n",
    "    \"\"\"\n",
    "    Decides whether the agent should retrieve more information or end the process.\n",
    "\n",
    "    This function checks the last message in the state for a function call. If a function call is\n",
    "    present, the process continues to retrieve information. Otherwise, it ends the process.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state of the agent, including all messages.\n",
    "\n",
    "    Returns:\n",
    "        str: A decision to either \"continue\" the retrieval process or \"end\" it.\n",
    "    \"\"\"\n",
    "    print(\"---DECIDE TO RETRIEVE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if \"function_call\" not in last_message.additional_kwargs:\n",
    "        print(\"---DECISION: DO NOT RETRIEVE / DONE---\")\n",
    "        return \"end\"\n",
    "    # Otherwise there is a function call, so we continue\n",
    "    else:\n",
    "        print(\"---DECISION: RETRIEVE---\")\n",
    "        return \"continue\"\n",
    "\n",
    "\n",
    "### Nodes\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state):\n",
    "    \"\"\"\n",
    "    Invokes the agent model to generate a response based on the current state.\n",
    "\n",
    "    This function calls the agent model to generate a response to the current conversation state.\n",
    "    The response is added to the state's messages.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state of the agent, including all messages.\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the new message added to the list of messages.\n",
    "    \"\"\"\n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    response = model_with_functions.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Define the function to execute tools\n",
    "def call_tool(state):\n",
    "    \"\"\"\n",
    "    Executes a tool based on the last message's function call.\n",
    "\n",
    "    This function is responsible for executing a tool invocation based on the function call\n",
    "    specified in the last message. The result from the tool execution is added to the conversation\n",
    "    state as a new message.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state of the agent, including all messages.\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the new function message added to the list of messages.\n",
    "    \"\"\"\n",
    "    print(\"---EXECUTE RETRIEVAL---\")\n",
    "    messages = state[\"messages\"]\n",
    "    # Based on the continue condition\n",
    "    # we know the last message involves a function call\n",
    "    last_message = messages[-1]\n",
    "    # We construct an ToolInvocation from the function_call\n",
    "    action = ToolInvocation(\n",
    "        tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
    "        tool_input=json.loads(\n",
    "            last_message.additional_kwargs[\"function_call\"][\"arguments\"]\n",
    "        ),\n",
    "    )\n",
    "    # We call the tool_executor and get back a response\n",
    "    response = tool_executor.invoke(action)\n",
    "    # print(type(response))\n",
    "    # We use the response to create a FunctionMessage\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [function_message]}\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)  # agent\n",
    "workflow.add_node(\"action\", call_tool)  # retrieval\n",
    "\n",
    "\n",
    "# Call agent node to decide to retrieve or not\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Decide whether to retrieve\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    # Assess agent decision\n",
    "    should_retrieve,\n",
    "    {\n",
    "        # Call tool node\n",
    "        \"continue\": \"action\",\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge('action', 'agent')\n",
    "\n",
    "# Compile\n",
    "agent = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf783df-f4f5-48be-8388-62441c11d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "            content=\"What is the future of insurance?\"\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "\n",
    "for output in agent.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint.pprint(f\"Output from node '{key}':\")\n",
    "        pprint.pprint(\"---\")\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "    pprint.pprint(\"\\n---\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbcde06-3184-42fe-add5-b3cd082f162b",
   "metadata": {},
   "source": [
    "## Try out different questions with the document provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e81b8-3d00-4104-b354-d908aebc7f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "            content=\"...\" ## write the question instead of three dots.\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "\n",
    "for output in agent.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint.pprint(f\"Output from node '{key}':\")\n",
    "        pprint.pprint(\"---\")\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "    pprint.pprint(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bc64e8-079c-4b27-811d-f462dddc9150",
   "metadata": {},
   "source": [
    "# TODO: Chatbot with RAG capability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2495a43e-0dd1-48e7-8bfe-0bd9965dcf07",
   "metadata": {},
   "source": [
    "Finally, we want to create a chat bot interface for our agent. To do so, we use the ***[holoviz Panel library](https://panel.holoviz.org/index.html)*** and create a class for the chat bot. Fill in the TODO parts of the code to get the chatbot up and running and answer user questions regarding the PDF file. The chatbot class uses the same agent that is defined above. Therefore, \n",
    "#### !!Make sure to run all the cells above for the agent to work properly\n",
    "\n",
    "Fill in the blank where indicated with # comment sign and complete the chatbot class and functions to see the chatbot in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e775b1c9-a126-48ee-807f-7e4857f28392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "import fitz\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "import param\n",
    "import re\n",
    "from langchain_core.messages.function import FunctionMessage\n",
    "from langchain.schema.messages import AIMessage\n",
    "from panel.chat import ChatMessage\n",
    "\n",
    "pn.extension()\n",
    "\n",
    "def chat_handler(contents, user, instance):\n",
    "    # TODO: Try playing around with ChatMessage class to create fancy responses.\n",
    "    # use the instance.generate_response(contents) function to return the answer to the user. \n",
    "\n",
    "    return instance.generate_response(contents)\n",
    "\n",
    "class PDFChatBot(pn.chat.ChatInterface):\n",
    "    \"\"\"\n",
    "    A HoloViz Panel extension providing a front end for a chatbot equipped with RAG tool.\n",
    "\n",
    "    This class extends the `pn.chat.ChatInterface` widget to integrate with a chatbot interface\n",
    "    implemented in Python. It provides a user-friendly chat interface within a Panel\n",
    "    application, allowing users to interact with the underlying chatbot.\n",
    "\n",
    "    Attributes:\n",
    "    -----------\n",
    "    callback: function\n",
    "        The function to handle the response to the user chat message.\n",
    "        \n",
    "    callback_user: str\n",
    "        The name of the chatbot user.\n",
    "\n",
    "    \n",
    "\n",
    "    Methods:\n",
    "    --------\n",
    "    switch_source_tab:\n",
    "        Switches the active tab to show the source page.\n",
    "    layout:\n",
    "        Returns the Panel layout containing the chat interface and other components.\n",
    "    generate_response:\n",
    "        Generates a response based on the user query and chat history.\n",
    "    render_page:\n",
    "        Renders a specific page of a PDF file as an image.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, *objects, **params):\n",
    "        \"\"\"\n",
    "        Initialize the PDFChatBot.\n",
    "        \"\"\"\n",
    "        self.callback = chat_handler\n",
    "        self.callback_user = 'Assistant'\n",
    "        super(PDFChatBot, self).__init__( *objects, **params)\n",
    "\n",
    "\n",
    "\n",
    "        ##############################################################\n",
    "        ## The page numbers of the returned source material from retrieval engine\n",
    "        ## an array to keep track of chat history\n",
    "        ## the langchain agent defined above\n",
    "        \n",
    "        self.srouce_page_num = [0, 1, 2]\n",
    "        self.chat_history = []\n",
    "        self.agent = agent\n",
    "        ##############################################################\n",
    "\n",
    "        \n",
    "        \n",
    "        self.source_images = [pn.pane.Image(width=500) for _ in range(3)]\n",
    "        \n",
    "\n",
    "        self.source_pane = pn.layout.Row(*self.source_images)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.chage_source_tab_button = pn.widgets.Button(name=\"Show source\", button_type='primary')\n",
    "        # Connect the button click event to the method\n",
    "        self.chage_source_tab_button.on_click(self.switch_source_tab)\n",
    "\n",
    "\n",
    "        self.tabs = pn.Tabs(('Conversation', self), ('Show source page', self.source_pane))\n",
    "        \n",
    "        self.render_page()\n",
    "\n",
    "    ##############################################################\n",
    "    ### Compelete the below function definition.\n",
    "    ## the aim of the function is to answer the input user query using self.agent.\n",
    "    ## if the function call has happened, make the necessary adjustments to update the source pages.\n",
    "    \n",
    "    def generate_response(self, query):\n",
    "        ##TODO: complete this function to generate the response to the user query, \n",
    "        ## Determine whether the openAI function has been called.\n",
    "        \"\"\"\n",
    "        Generate a response based on user query and chat history.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        query : str\n",
    "            User's query.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        answer : str\n",
    "            Returned output from the agent.\n",
    "        function_called : bool\n",
    "            Indicates if a function was called in the response.\n",
    "        \"\"\"\n",
    "        inputs = {\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=query\n",
    "                )\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        # TODO: check for function calls and adjust the reponse of the model accordingly.\n",
    "        # The langchain agent is in class property self.agent, you can call it with self.agent.invoke(inputs) \n",
    "        # If the retrieval function is called you need to update the source page numbers from the reponse.\n",
    "        answer = 'default response'\n",
    "        return answer\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def switch_source_tab(self, event):\n",
    "        \"\"\"\n",
    "        Switches the active tab to show the source page.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        event : Event\n",
    "            The event object representing the button click event.\n",
    "        \"\"\"\n",
    "        self.tabs.active = 1 if self.tabs.active == 0 else 1\n",
    "\n",
    "    def layout(self):\n",
    "        \"\"\"\n",
    "        Returns the Panel layout containing the chat interface and other components.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        Panel: The Panel layout containing the chat interface and other components.\n",
    "        \"\"\"\n",
    "        return self.tabs\n",
    "\n",
    "    def render_page(self):\n",
    "        \"\"\"\n",
    "        Renders source pages of a PDF file in the source tab.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        None\n",
    "        \"\"\"\n",
    "        doc = fitz.open(doc_address)\n",
    "\n",
    "        \n",
    "        for i, pdf_page in enumerate(self.srouce_page_num[:3]):\n",
    "            page = doc[pdf_page]\n",
    "            pix = page.get_pixmap(matrix=fitz.Matrix(300 / 72, 300 / 72))\n",
    "            image = Image.frombytes('RGB', [pix.width, pix.height], pix.samples)\n",
    "            self.source_images[i].param.update(object=image)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21200d38-8c14-47dd-ac00-481ba955d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = PDFChatBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bbfc0a-608a-4f93-8a1d-d88ef2c3e563",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d526ca23-4fc4-47fe-b9ee-15c747a1de02",
   "metadata": {},
   "source": [
    "# You can try with a new pdf file. Upload your pdf file and change the file address at the top of this notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
